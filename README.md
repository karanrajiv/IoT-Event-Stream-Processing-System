
# IoT Event Stream Processing System

This project simulates and processes real-time IoT sensor data using Kafka, Spark Streaming, Redis, FastAPI, and Streamlit. It includes a data ingestion pipeline, streaming processor, REST API, and live dashboard for monitoring alerts.

## ğŸš€ Features

- **Kafka Producer**: Generates mock temperature/humidity readings from virtual sensors.
- **Kafka Consumer**: Monitors the stream and pushes high-temperature alerts to Redis.
- **Spark Streaming**: Parses and displays streaming sensor data in real-time.
- **FastAPI**: Exposes a REST API to query historical alerts.
- **Streamlit Dashboard**: Live visualization of alerts and sensor trends.
- **GitHub Actions CI**: Linting workflow for Python codebase.

## ğŸ§° Tech Stack

- Apache Kafka, Zookeeper
- Apache Spark (Structured Streaming)
- Redis
- FastAPI, Streamlit
- Docker, Docker Compose
- Python 3.9

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ api/                  # FastAPI server
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ consumer/             # Kafka consumer
â”‚   â””â”€â”€ consumer.py
â”œâ”€â”€ dashboard/            # Streamlit app
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ docker/               # Docker Compose setup
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ docs/                 # Documentation
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ producer/             # Kafka producer
â”‚   â””â”€â”€ producer.py
â”œâ”€â”€ streaming/            # Spark Streaming job
â”‚   â””â”€â”€ streaming_job.py
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ ci.yml        # GitHub Actions workflow
```

## ğŸ§ª How to Run

### 1. Start the Infrastructure
```bash
docker-compose -f docker/docker-compose.yml up -d
```

### 2. Start Components
```bash
# Terminal 1 - Start Kafka Producer
python producer/producer.py

# Terminal 2 - Start Kafka Consumer
python consumer/consumer.py

# Terminal 3 - Start Spark Streaming Job
spark-submit streaming/streaming_job.py

# Terminal 4 - Start FastAPI Server
uvicorn api.main:app --reload

# Terminal 5 - Run Streamlit Dashboard
streamlit run dashboard/app.py
```

## ğŸŒ¡ï¸ Alert Logic

- Temperature > 30Â°C triggers an alert
- Alerts are stored in Redis under the key `alerts`
- Retrieved via API or visualized in the dashboard

## ğŸ§ª CI Integration

GitHub Actions runs linting using `flake8` on all Python files on every push to `main`.

## ğŸ“¬ API Endpoint

- `GET /alerts` - returns all stored alerts as JSON

## ğŸ“Š Dashboard

The dashboard continuously polls Redis and displays:
- Real-time temperature and humidity line chart
- Tabular view of recent alerts

## ğŸ“ License

MIT License
